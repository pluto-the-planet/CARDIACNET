# -*- coding: utf-8 -*-
"""Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KqZrAt--JVDZvmWah9fitDMhrW3ScE9O
"""

from data import train_gen, val_gen

db_train = train_gen(base_dir='/kaggle/working/training',
                            split="train",
                            num=None,
                            transform=None,sample_list=sample_list)
#total 1312 samples
images=[]
for i in range(0,len(db_train)):
    images+=db_train[i]['image']
images=np.stack(images, axis=0)

labels=[]
for i in range(0,len(db_train)):
    labels+=db_train[i]['label']
labels=np.stack(labels, axis=0)

images=images.reshape((1902, 256, 256, 1))
labels=labels.reshape((1902, 256, 256, 1))

db_val = val_gen(base_dir='/kaggle/working/testing/',
                            split="val",
                            num=None,
                            transform=None,sample_list_val=sample_list_val)

images_val=[]
for i in range(0,len(db_val)):
    images_val+=db_val[i]['image']
images_val=np.stack(images_val, axis=0)
labels_val=[]
for i in range(0,len(db_val)):
    labels_val+=db_val[i]['label']
labels_val=np.stack(labels_val, axis=0)

images_val=images_val.reshape((1076, 256, 256, 1))
labels_val=labels_val.reshape((1076, 256, 256, 1))

import tensorflow as tf
from tensorflow.keras import backend as K
​
def dice_coef(y_true, y_pred, smooth=1):
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(y_pred, 'float32')

    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)

    intersection = K.sum(y_true_f * y_pred_f)
    union = K.sum(y_true_f) + K.sum(y_pred_f)

    dice = (2. * intersection + smooth) / (union + smooth)
    return dice
​
​
def iou_coef(y_true, y_pred, smooth=1):
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(y_pred, 'float32')

    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)

    intersection = K.sum(y_true_f * y_pred_f)
    total = K.sum(y_true_f) + K.sum(y_pred_f)
    union = total - intersection

    iou = (intersection + smooth) / (union + smooth)
    return iou

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Activation, Multiply, Add, BatchNormalization, Lambda

def attention_gate(x, g, inter_shape):
    theta_x = Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)
    phi_g = Conv2D(inter_shape, (1, 1), padding='same')(g)

    # Ensure the shapes match for addition
    theta_x = UpSampling2D(size=(2, 2))(theta_x)

    add_xg = Add()([theta_x, phi_g])
    act_xg = Activation('relu')(add_xg)
    psi = Conv2D(1, (1, 1), padding='same')(act_xg)
    sigmoid_xg = Activation('sigmoid')(psi)

    # Resize psi to match the shape of the original input x
    upsample_psi = Lambda(lambda x: tf.image.resize(x, tf.shape(x)[1:3]))(sigmoid_xg)

    y = Multiply()([x, upsample_psi])
    result = Conv2D(inter_shape, (1, 1), padding='same')(y)
    result_bn = BatchNormalization()(result)
    return result_bn

def Attention_UNetPP(input_size=(256, 256, 1)):
    inputs = Input(input_size)

    # Down-sampling path
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)

    # Up-sampling path
    up6 = UpSampling2D(size=(2, 2))(conv5)
    att6 = attention_gate(conv4, up6, 512)
    merge6 = concatenate([conv4, att6], axis=3)
    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(merge6)
    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)

    up7 = UpSampling2D(size=(2, 2))(conv6)
    att7 = attention_gate(conv3, up7, 256)
    merge7 = concatenate([conv3, att7], axis=3)
    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(merge7)
    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)

    up8 = UpSampling2D(size=(2, 2))(conv7)
    att8 = attention_gate(conv2, up8, 128)
    merge8 = concatenate([conv2, att8], axis=3)
    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(merge8)
    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)

    up9 = UpSampling2D(size=(2, 2))(conv8)
    att9 = attention_gate(conv1, up9, 64)
    merge9 = concatenate([conv1, att9], axis=3)
    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(merge9)
    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)

    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)

    model = Model(inputs, conv10)

    return model

model = Attention_UNetPP(input_size=(256, 256, 1))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',dice_coef, iou_coef])

model.summary()

history=model.fit(images, labels, epochs=25, batch_size=32, validation_data=(images_val,labels_val))
# Save the model weights
model.save_weights('model_weights.weights.h5')

evaluation = model.evaluate(images_val, labels_val)
print(f"Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}")

import matplotlib.pyplot as plt

predictions = model.predict(images_val)

# Visualize some predictions alongside actual images
for i in range(5):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 3, 1)
    plt.title("Input Image")
    plt.imshow(images_val[i].reshape(256, 256), cmap='gray')

    plt.subplot(1, 3, 2)
    plt.title("Actual Mask")
    plt.imshow(labels_val[i].reshape(256, 256), cmap='gray')

    plt.subplot(1, 3, 3)
    plt.title("Predicted Mask")
    plt.imshow(predictions[i].reshape(256, 256), cmap='gray')

    plt.show()